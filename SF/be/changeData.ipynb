{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c676fb-2bfc-46c7-9dd8-886c1947a9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d04cf4-c662-4c9a-a2fd-d244826dd9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 음성데이터 argumentation을 통해서 데이터 수 늘리기 및 오버피팅 방지\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data):\n",
    "    return librosa.effects.time_stretch(data, rate=0.8)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitchs(data, sampling_rate, n_steps):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd58da52-bd72-4eba-aead-b16c8ce1f021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(data, sampling_rate):\n",
    "\n",
    "    result = np.array([])\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    # rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    # result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    # mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sampling_rate).T, axis=0)\n",
    "    # result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ca86988-1be3-42c5-96d9-39f2998768e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 음성의 특성을 추출한 데이터를 축적하는 함수 (Argumentation된 데이터도 같이)\n",
    "def get_features(path):\n",
    "    # duration과 offset은 각 오디오 파일의 시작과 끝에서 오디오가 없는 것을 처리\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # 원래데이터\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "#     # 노이즈가 추가된 데이터\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # 병렬적으로 추가\n",
    "\n",
    "#     # 피칭및 스트레칭된 데이터\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitchs(new_data, sample_rate, 0.7)\n",
    "    res3 = extract_features(data_stretch_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # 병렬적으로 추가\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "803daa7b-b783-44e3-804d-04209b3c4933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "feature = get_features(\"soundData/test/su14.wav\")\n",
    "for ele in feature:\n",
    "    X.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f21f7c7-7e9a-49e7-8abf-662a0752be9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Features = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d64a1245-d748-4b5c-aa22-f1c48ef2ba64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = Features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ecbccec-b22f-4463-9718-f7a0423a2f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 20)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c6aca88-1d2d-49d0-8ec5-769ab2b967ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d89109de-86ca-405f-bffd-488c44f1bdba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 20)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a8c4a00-3667-4f8a-a1d2-7a5b4bc18de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89d4d195-4a12-4d5e-a1a0-7979d1b84cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model('sound_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef4088e7-55c4-47dc-a5df-46effe2460f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "314d0025-7101-4188-b596-158957f15b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b5cb4db-3934-4779-bc72-e9a3427c1e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3451498-eb87-4bd6-8d19-8ac8f853bdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff1bc905-14f6-495a-8453-cedfbbaadb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      sadness\n",
       "1      neutral\n",
       "2    happiness\n",
       "Name: Predicted Labels, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Predicted Labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6220a2-3987-4bf7-9a79-fc1a9476b338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
